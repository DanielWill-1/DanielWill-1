{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+F495RxGJw/xqkyabKKnc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielWill-1/DanielWill-1/blob/main/VAE(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mQdAgkkF7DxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers,Model\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.losses import MeanSquaredError, KLDivergence, binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import cov,trace,iscomplexobj, asarray\n",
        "from scipy.linalg import sqrtm\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Il04tF9L1b",
        "outputId": "ef145fa2-536d-4ac1-c8c1-c02f9d71174c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')/ 255.0\n",
        "x_test=x_test.astype('float32')/ 255.0"
      ],
      "metadata": {
        "id": "EfMo8U2j9N5b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim= 1024\n",
        "image_shape=x_train[0].shape\n",
        "mse_loss=MeanSquaredError()\n",
        "kl_loss=KLDivergence()"
      ],
      "metadata": {
        "id": "Dam1KvLg9TFb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "  def __init__(self,latent_dim, image_shape,beta):\n",
        "    super(VAE,self).__init__()\n",
        "    self.latent_dim=latent_dim\n",
        "    self.image_shape=image_shape\n",
        "    self.beta=beta\n",
        "\n",
        "    self.encoder=tf.keras.Sequential([\n",
        "        layers.Input(shape=image_shape, name=\"Encoder_Input_Layer\"),\n",
        "        layers.Conv2D(32,3,strides=2,activation=\"relu\", padding='same', name=\"Encoder_Conv2D_2\"),\n",
        "        layers.Conv2D(64,3,strides=2,activation=\"relu\", padding='same', name=\"Encoder_Conv2D_4\"),\n",
        "        layers.Conv2D(128,3,strides=2,activation=\"relu\", padding='same', name=\"Encoder_Conv2D_6\"),\n",
        "        layers.Flatten(name=\"Encoder_Flatten\"),\n",
        "\n",
        "    ])\n",
        "\n",
        "    self.z_mean=layers.Dense(latent_dim,name=\"z_mean\")\n",
        "    self.z_log_var=layers.Dense(latent_dim,name=\"z__log_var\")\n",
        "\n",
        "    self.decoder=tf.keras.Sequential([\n",
        "        layers.InputLayer(input_shape=(latent_dim,)),\n",
        "        layers.Dense(8*8*64, activation='relu'),\n",
        "        layers.Reshape((8, 8, 64)),\n",
        "        layers.Conv2DTranspose(64,kernel_size=3,strides=2,activation='relu',padding='same'),\n",
        "        layers.Conv2DTranspose(32,kernel_size=3,strides=2,activation='relu',padding='same'),\n",
        "        layers.Conv2DTranspose(3,kernel_size=3,strides=1,activation='sigmoid',padding='same'),\n",
        "    ])\n",
        "\n",
        "    self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "    self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "    self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "  def encode(self,data):\n",
        "    x=self.encoder(data)\n",
        "    z_mean,z_log_var= self.z_mean(x),self.z_log_var(x)\n",
        "    return z_mean,z_log_var\n",
        "\n",
        "  def reparameterize(self,z_mean,z_log_var):\n",
        "    batch=tf.shape(z_mean)[0]\n",
        "    dim=tf.shape(z_mean)[1]\n",
        "    epsilon=tf.keras.backend.random_normal(shape=(batch,dim))\n",
        "    z=z_mean+tf.exp(0.5*z_log_var)*epsilon\n",
        "    return z\n",
        "\n",
        "  def call(self,x):\n",
        "    mean,log_var=self.encode(x)\n",
        "    z=self.reparameterize(mean,log_var)\n",
        "    x_recon=self.decode(z)\n",
        "    return x_recon, mean, log_var\n",
        "\n",
        "  def decode(self,data):\n",
        "    return self.decoder(data)\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def recon_loss(self,data,reconstruction):\n",
        "    return tf.reduce_mean(binary_crossentropy(data, reconstruction))\n",
        "\n",
        "  def kl_divergence(self,Z_log_var, Z_mu):\n",
        "    kl=-0.5*tf.reduce_mean(1+Z_log_var-Z_mu**2-tf.math.exp(Z_log_var))\n",
        "    return self.beta*kl\n",
        "\n",
        "  def train_step(self,data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var=self.encode(data)\n",
        "      z=self.reparameterize(z_mean,z_log_var)\n",
        "      reconstruction=self.decode(z)\n",
        "      reconstruction_loss=self.recon_loss(data,reconstruction)\n",
        "      kl_loss=self.kl_divergence(z_log_var, z_mean)\n",
        "      trial_loss=reconstruction_loss+kl_loss\n",
        "    grads=tape.gradient(trial_loss,self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads,self.trainable_weights))\n",
        "    self.total_loss_tracker.update_state(trial_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "    return{\n",
        "        \"loss\":self.total_loss_tracker.result(),\n",
        "        \"reconstruction_loss\":self.reconstruction_loss_tracker.result(),\n",
        "        \"kl_loss\":self.kl_loss_tracker.result(),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "y8V_Q4tL9QFO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae=VAE(latent_dim,image_shape,0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0__GvL3r9aCl",
        "outputId": "187d779e-44e4-4dc3-d076-d43c0882f0ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "early_stopping=EarlyStopping(monitor='loss',patience=10,verbose=1)\n",
        "history=vae.fit(x_train,epochs=50,batch_size=512,callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-luheDr9bY9",
        "outputId": "92c53179-6035-42ce-efd6-aec72d733004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - kl_loss: 6.7821e-04 - loss: 0.6872 - reconstruction_loss: 0.6866\n",
            "Epoch 2/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - kl_loss: 0.0080 - loss: 0.6278 - reconstruction_loss: 0.6198\n",
            "Epoch 3/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - kl_loss: 0.0107 - loss: 0.6185 - reconstruction_loss: 0.6077\n",
            "Epoch 4/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - kl_loss: 0.0124 - loss: 0.6145 - reconstruction_loss: 0.6021\n",
            "Epoch 5/50\n",
            "\u001b[1m 8/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 2s/step - kl_loss: 0.0131 - loss: 0.6114 - reconstruction_loss: 0.5983"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sal3o02y9cni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images_from_latent_vectors(vae, num_images_to_generate):\n",
        "  random_latent_vectors = np.random.normal(size=(num_images_to_generate, latent_dim))\n",
        "  generated_images = vae.decoder.predict(random_latent_vectors)\n",
        "  return generated_images\n",
        "generated_images = generate_images_from_latent_vectors(vae, 20)"
      ],
      "metadata": {
        "id": "wgpu3wnY7vsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_real_and_generated_images(real_images, generated_images, num_images_to_generate):\n",
        "    plt.figure(figsize=(20,10))\n",
        "\n",
        "    for i in range(num_images_to_generate):\n",
        "        plt.subplot(2, num_images_to_generate, i + 1)\n",
        "        plt.imshow(real_images[i])\n",
        "        plt.title('real image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, num_images_to_generate, i + 1 + num_images_to_generate)\n",
        "        plt.imshow(generated_images[i])        plt.title('generated image')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_real_and_generated_images(x_test, generated_images, 5)"
      ],
      "metadata": {
        "id": "GUsYQLh59fDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kl_loss = history.history['kl_loss']\n",
        "reconstruction_loss = history.history['reconstruction_loss']\n",
        "total_loss = history.history['loss']\n"
      ],
      "metadata": {
        "id": "dK-TYu1t_qxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}